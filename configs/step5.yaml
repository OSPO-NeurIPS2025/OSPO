# Step 5

base:
  save_path: /nas2/checkpoints/janus_dpo
  exp_name: final/0522_ablation_silmm_random_3_pair_selection
  note: batch size 128
  world_size: 2
  resume:
  
model:
  model_path: /nas2/checkpoints/Janus-Pro-7B 
  parallel_size: 1                     
  image_token_num_per_image: 576       
  cache_dir: /nas2/checkpoints/hf_cache_yj

use_peft: True 
use_ds: False

lora:
  lora_rank: 32
  lora_alpha: 64
  lora_dropout: 0.05
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "down_proj", "up_proj"]
  modules_to_save: # Keeps selected layers trainable without applying LoRA. (그러나 이 모델의 경우 특별히 추가할 필요 없음.)

dataset:
  train:
    batch_size: 16 # A100 기준 최대 올라가는 배치 크기: 16
    num_workers: 4
    data_path: /home/yjoh/project/Janus_DPO/ablation/best_of_n_our_scoring/train_dataset_silmm_random_3.json
    img_path:
    num_samples:              # 데이터셋 중 N개의 데이터만 추출해서 사용할 경우 int 로 기입
    chosen_reject_swap:       # 디폴트 False
  val:
    batch_size: 1
    num_workers: 1
    text_path:
    img_path:
    s_idx:
    e_idx: 5
    # 일종의 generation cfg 역할 (default)
    temperature: 1
    cfg_weight: 5


optimizer:
  init_lr: 4e-5 # 4e-4 # 4e-5 
  betas: [0.9, 0.95]
  weight_decay: 0.00 # 0.05
  eps: 1e-8
  scheduler_type: constant # cosine
  min_lr: 1e-6 # constant scheduler 에서는 사용되지 않음


experiment:
  seed: 42
  precision: bf16 # 32 / bf16

  warmup_ratio: 0 # 0.01
  gradient_clip_val: 1.0
  enable_checkpointing: True
  gradient_checkpointing: True # language model 만 checkpointing
  gradient_accumulation_steps: 4
  max_training_steps: 100 # total bsz 64 기준 250 step = 1 epoch
  save_steps: 100
  log_steps: 5
  val_steps: 100

  freeze:
    vision_model: True
    aligner: True
    gen_vision_model: True
    gen_aligner: True
    gen_head: True
    gen_embed: True
    language_model: False


tokenizer:
  max_length: 2048
  max_prompt_length: 1024
  max_completion_length: 
  max_target_length: 
  truncation_mode: keep_end 
  truncation_side: left 
  label_pad_token_id: -100  


algo:
  beta: 10 
  gamma_beta_ratio: 0.5 
  sft_weight: 0
  label_smoothing: 0 
  loss_type: sigmoid 
  disable_dropout: True 
